{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GPU 확인"
      ],
      "metadata": {
        "id": "vKXMRFM9_7Zv"
      },
      "id": "vKXMRFM9_7Zv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47277776-44f4-4f44-abc1-7d73642052b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47277776-44f4-4f44-abc1-7d73642052b9",
        "outputId": "7fef2839-6fb5-4764-9ec1-784d7444d572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 460223101166961888\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14415560704\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 1956348762170138845\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 구글 드라이브 임포트"
      ],
      "metadata": {
        "id": "AzxdJMmm_5BP"
      },
      "id": "AzxdJMmm_5BP"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JCYx3LO6VaT",
        "outputId": "af29493c-a2f3-49b3-c88a-1c1cb6873e17"
      },
      "id": "6JCYx3LO6VaT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db7c26a1-3f1a-4782-b497-19a86f9e897b",
      "metadata": {
        "tags": [],
        "id": "db7c26a1-3f1a-4782-b497-19a86f9e897b"
      },
      "source": [
        "# 전처리 (생략)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45b29f8c-c4ba-42e8-b5a3-b993858546b9",
      "metadata": {
        "id": "45b29f8c-c4ba-42e8-b5a3-b993858546b9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d75fe168-0d5f-427a-820c-d4cec22ef034",
      "metadata": {
        "id": "d75fe168-0d5f-427a-820c-d4cec22ef034"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad61bc48-ab4a-4d95-9d72-d4aa22e8cda4",
      "metadata": {
        "id": "ad61bc48-ab4a-4d95-9d72-d4aa22e8cda4"
      },
      "source": [
        "# 학습코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26ec9503-69c7-4ed4-9e50-1b4ef9e58be2",
      "metadata": {
        "id": "26ec9503-69c7-4ed4-9e50-1b4ef9e58be2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tqdm import tqdm\n",
        "from tqdm import trange\n",
        "\n",
        "from numba import jit, cuda, prange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2da2715c-3218-49f9-b972-09f4e6a66b1e",
      "metadata": {
        "id": "2da2715c-3218-49f9-b972-09f4e6a66b1e"
      },
      "outputs": [],
      "source": [
        "labelTable = [\"cap_and_hat\", \"outerwear\", \"tops\", \"bottoms\", \"shoes\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cdf0afe-1665-42ac-b7ac-3fdfe8a3005e",
      "metadata": {
        "id": "2cdf0afe-1665-42ac-b7ac-3fdfe8a3005e"
      },
      "outputs": [],
      "source": [
        "xDatas = np.load(f'{BASE_DIR}/xDatas32.npy')\n",
        "yDatas = np.load(f'{BASE_DIR}/yDatas.npy')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(xDatas))\n",
        "print(len(yDatas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoG16c9fZt_m",
        "outputId": "b77dbe95-0a62-4928-a6c5-7d6f18b85e7e"
      },
      "id": "xoG16c9fZt_m",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30000\n",
            "30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67bef63c-a764-422a-85c1-4368cee269dc",
      "metadata": {
        "id": "67bef63c-a764-422a-85c1-4368cee269dc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6b57768-a129-40f9-98dc-77b900bb64c5",
      "metadata": {
        "id": "a6b57768-a129-40f9-98dc-77b900bb64c5"
      },
      "outputs": [],
      "source": [
        "xTrain, xValidation, yTrain, yValidation = train_test_split(xDatas, yDatas, test_size=0.2, stratify=yDatas, random_state=1120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d4afdc-90cf-4aa5-aa63-2f1f3e09de05",
      "metadata": {
        "id": "28d4afdc-90cf-4aa5-aa63-2f1f3e09de05"
      },
      "outputs": [],
      "source": [
        "imRows = 32\n",
        "imCols = 32\n",
        "\n",
        "inputShape = (imRows, imCols, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fede18e6-1912-478a-bad1-99176460ce6f",
      "metadata": {
        "id": "fede18e6-1912-478a-bad1-99176460ce6f"
      },
      "outputs": [],
      "source": [
        "# with tf.device(\"CPU:0\"):\n",
        "xTrain = tf.convert_to_tensor(xTrain, dtype=tf.float32)\n",
        "xValidation = tf.convert_to_tensor(xValidation, dtype=tf.float32)\n",
        "yTrain = tf.one_hot(yTrain, depth=len(np.unique(yTrain)))\n",
        "yValidation = tf.one_hot(yValidation, depth=len(np.unique(yValidation)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aee9950-9d2c-4715-b7c1-33498c39bacc",
      "metadata": {
        "id": "9aee9950-9d2c-4715-b7c1-33498c39bacc"
      },
      "outputs": [],
      "source": [
        "num_classes = 5   #10개 클래스 기억\n",
        "model = Sequential()   #순차적으로 레이어를 더해주는 명령\n",
        "\n",
        "#첫번째 컨볼루션 레이어\n",
        "#입력 레이어\n",
        "#컨볼루션 레이어의 컨볼루션 연산과 폴링 연산 설정\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', kernel_initializer='he_normal', padding=\"valid\",\n",
        "                 input_shape=inputShape))   #서로 다른 64개의 필터를 3x3사이즈로 설정하여 연산함. 이때, 최적화함수는 relu(음수는 0으로 반환), 패딩은 사이즈를 작게 두는 valid 옵션 사용\n",
        "model.add(MaxPooling2D(2))   #폴링필터를 2x2로 설정하여 연산함. MaxPooling2D(2,2)와 같음\n",
        "model.add(Dropout(0.3))   #30%의 노드를 삭제함\n",
        "\n",
        "#두번째 컨볼루션 레이어\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', kernel_initializer='he_normal', padding='valid'))\n",
        "model.add(MaxPooling2D(2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "#세번째 컨볼루션 레이어 \n",
        "model.add(Conv2D(128, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "#첫번째 완전 연결(Fully Connected) 레이어\n",
        "model.add(Flatten())   #다차원을 1차원으로 변경해주는 명령\n",
        "\n",
        "#두번째 완전 연결(Fully Connected) 레이어, \n",
        "model.add(Dense(128, kernel_initializer='he_normal', activation='relu'))   #노드의 갯수가 256개인 히든레이어\n",
        "\n",
        "#세번째 완전 연결(Fully Connected) 레이어, \n",
        "model.add(Dense(256, kernel_initializer='he_normal', activation='relu'))\n",
        "\n",
        "#네번째 완전 연결(Fully Connected) 레이어\n",
        "#출력 레이어\n",
        "model.add(Dense(num_classes, activation='softmax'))   #출력 레이어의 노드의 갯수는 분류할 10개 클래스와 같아야 함, softmax() 함수는 학습데이터에 얼마나 가까워졌는지 정도를 보여주는 방법임"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c42cc6d-f143-4e5a-89ce-e78709954696",
      "metadata": {
        "id": "0c42cc6d-f143-4e5a-89ce-e78709954696"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78aae4e2-03c9-4d0f-8449-c58f91022042",
      "metadata": {
        "id": "78aae4e2-03c9-4d0f-8449-c58f91022042"
      },
      "outputs": [],
      "source": [
        "#모델 학습방식 환경설정(최적화함수, 손실함수, 평가지표)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"categorical_crossentropy\",     \n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d81e8a7-3649-4b92-97aa-7e33181c3275",
      "metadata": {
        "id": "3d81e8a7-3649-4b92-97aa-7e33181c3275",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59c721de-d0e9-4461-aee2-aa0229e1137e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "200/200 [==============================] - 11s 9ms/step - loss: 30.8304 - accuracy: 0.4745 - val_loss: 1.5728 - val_accuracy: 0.6082\n",
            "Epoch 2/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.1491 - accuracy: 0.5782 - val_loss: 1.4821 - val_accuracy: 0.6118\n",
            "Epoch 3/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0756 - accuracy: 0.5990 - val_loss: 1.3979 - val_accuracy: 0.6115\n",
            "Epoch 4/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0588 - accuracy: 0.6063 - val_loss: 1.3226 - val_accuracy: 0.6117\n",
            "Epoch 5/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0470 - accuracy: 0.6083 - val_loss: 1.2864 - val_accuracy: 0.6117\n",
            "Epoch 6/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0442 - accuracy: 0.6088 - val_loss: 1.2530 - val_accuracy: 0.6117\n",
            "Epoch 7/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0387 - accuracy: 0.6092 - val_loss: 1.2239 - val_accuracy: 0.6117\n",
            "Epoch 8/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0338 - accuracy: 0.6104 - val_loss: 1.1982 - val_accuracy: 0.6117\n",
            "Epoch 9/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0283 - accuracy: 0.6101 - val_loss: 1.1751 - val_accuracy: 0.6117\n",
            "Epoch 10/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0271 - accuracy: 0.6105 - val_loss: 1.1535 - val_accuracy: 0.6117\n",
            "Epoch 11/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0275 - accuracy: 0.6104 - val_loss: 1.1379 - val_accuracy: 0.6117\n",
            "Epoch 12/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0256 - accuracy: 0.6105 - val_loss: 1.1160 - val_accuracy: 0.6117\n",
            "Epoch 13/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0250 - accuracy: 0.6103 - val_loss: 1.1090 - val_accuracy: 0.6117\n",
            "Epoch 14/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0252 - accuracy: 0.6103 - val_loss: 1.0802 - val_accuracy: 0.6117\n",
            "Epoch 15/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0231 - accuracy: 0.6111 - val_loss: 1.0664 - val_accuracy: 0.6117\n",
            "Epoch 16/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0205 - accuracy: 0.6109 - val_loss: 1.0592 - val_accuracy: 0.6117\n",
            "Epoch 17/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0229 - accuracy: 0.6110 - val_loss: 1.0400 - val_accuracy: 0.6117\n",
            "Epoch 18/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0195 - accuracy: 0.6106 - val_loss: 1.0343 - val_accuracy: 0.6117\n",
            "Epoch 19/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 1.0148 - accuracy: 0.6106 - val_loss: 1.0231 - val_accuracy: 0.6117\n",
            "Epoch 20/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.9633 - accuracy: 0.6409 - val_loss: 0.9362 - val_accuracy: 0.6483\n",
            "Epoch 21/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.8841 - accuracy: 0.6811 - val_loss: 0.8295 - val_accuracy: 0.7098\n",
            "Epoch 22/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.8586 - accuracy: 0.6935 - val_loss: 0.8007 - val_accuracy: 0.7173\n",
            "Epoch 23/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.8496 - accuracy: 0.6981 - val_loss: 0.8053 - val_accuracy: 0.7163\n",
            "Epoch 24/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.8379 - accuracy: 0.7040 - val_loss: 0.8011 - val_accuracy: 0.7168\n",
            "Epoch 25/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.8284 - accuracy: 0.7045 - val_loss: 0.7846 - val_accuracy: 0.7217\n",
            "Epoch 26/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.8209 - accuracy: 0.7078 - val_loss: 0.7776 - val_accuracy: 0.7257\n",
            "Epoch 27/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.8098 - accuracy: 0.7098 - val_loss: 0.7691 - val_accuracy: 0.7230\n",
            "Epoch 28/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.8059 - accuracy: 0.7120 - val_loss: 0.7738 - val_accuracy: 0.7233\n",
            "Epoch 29/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.8017 - accuracy: 0.7119 - val_loss: 0.7669 - val_accuracy: 0.7203\n",
            "Epoch 30/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7959 - accuracy: 0.7135 - val_loss: 0.7878 - val_accuracy: 0.7128\n",
            "Epoch 31/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7933 - accuracy: 0.7134 - val_loss: 0.7535 - val_accuracy: 0.7278\n",
            "Epoch 32/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7838 - accuracy: 0.7157 - val_loss: 0.7485 - val_accuracy: 0.7283\n",
            "Epoch 33/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7858 - accuracy: 0.7175 - val_loss: 0.7431 - val_accuracy: 0.7310\n",
            "Epoch 34/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7762 - accuracy: 0.7204 - val_loss: 0.7363 - val_accuracy: 0.7347\n",
            "Epoch 35/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7729 - accuracy: 0.7193 - val_loss: 0.7574 - val_accuracy: 0.7242\n",
            "Epoch 36/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7719 - accuracy: 0.7196 - val_loss: 0.7294 - val_accuracy: 0.7363\n",
            "Epoch 37/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7707 - accuracy: 0.7197 - val_loss: 0.7521 - val_accuracy: 0.7298\n",
            "Epoch 38/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7698 - accuracy: 0.7194 - val_loss: 0.7213 - val_accuracy: 0.7367\n",
            "Epoch 39/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7638 - accuracy: 0.7224 - val_loss: 0.7270 - val_accuracy: 0.7348\n",
            "Epoch 40/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7642 - accuracy: 0.7206 - val_loss: 0.7249 - val_accuracy: 0.7378\n",
            "Epoch 41/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7639 - accuracy: 0.7208 - val_loss: 0.7255 - val_accuracy: 0.7360\n",
            "Epoch 42/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7645 - accuracy: 0.7205 - val_loss: 0.7475 - val_accuracy: 0.7308\n",
            "Epoch 43/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7571 - accuracy: 0.7237 - val_loss: 0.7593 - val_accuracy: 0.7252\n",
            "Epoch 44/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7638 - accuracy: 0.7212 - val_loss: 0.7225 - val_accuracy: 0.7347\n",
            "Epoch 45/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7498 - accuracy: 0.7245 - val_loss: 0.7349 - val_accuracy: 0.7303\n",
            "Epoch 46/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7564 - accuracy: 0.7213 - val_loss: 0.7234 - val_accuracy: 0.7338\n",
            "Epoch 47/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7237 - accuracy: 0.7297 - val_loss: 0.7310 - val_accuracy: 0.7340\n",
            "Epoch 48/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7368 - accuracy: 0.7275 - val_loss: 0.6760 - val_accuracy: 0.7487\n",
            "Epoch 49/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7273 - accuracy: 0.7309 - val_loss: 0.7041 - val_accuracy: 0.7368\n",
            "Epoch 50/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7186 - accuracy: 0.7317 - val_loss: 0.6697 - val_accuracy: 0.7483\n",
            "Epoch 51/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7209 - accuracy: 0.7322 - val_loss: 0.6749 - val_accuracy: 0.7460\n",
            "Epoch 52/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7118 - accuracy: 0.7355 - val_loss: 0.6687 - val_accuracy: 0.7513\n",
            "Epoch 53/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7064 - accuracy: 0.7363 - val_loss: 0.6588 - val_accuracy: 0.7503\n",
            "Epoch 54/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.7045 - accuracy: 0.7363 - val_loss: 0.6781 - val_accuracy: 0.7475\n",
            "Epoch 55/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6992 - accuracy: 0.7380 - val_loss: 0.6480 - val_accuracy: 0.7540\n",
            "Epoch 56/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6921 - accuracy: 0.7389 - val_loss: 0.6429 - val_accuracy: 0.7532\n",
            "Epoch 57/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6925 - accuracy: 0.7394 - val_loss: 0.6537 - val_accuracy: 0.7493\n",
            "Epoch 58/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6928 - accuracy: 0.7382 - val_loss: 0.6432 - val_accuracy: 0.7523\n",
            "Epoch 59/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6927 - accuracy: 0.7391 - val_loss: 0.6755 - val_accuracy: 0.7368\n",
            "Epoch 60/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6906 - accuracy: 0.7408 - val_loss: 0.6527 - val_accuracy: 0.7492\n",
            "Epoch 61/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6832 - accuracy: 0.7420 - val_loss: 0.6421 - val_accuracy: 0.7528\n",
            "Epoch 62/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6749 - accuracy: 0.7433 - val_loss: 0.6355 - val_accuracy: 0.7528\n",
            "Epoch 63/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6792 - accuracy: 0.7412 - val_loss: 0.6454 - val_accuracy: 0.7532\n",
            "Epoch 64/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6749 - accuracy: 0.7419 - val_loss: 0.6351 - val_accuracy: 0.7583\n",
            "Epoch 65/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6732 - accuracy: 0.7440 - val_loss: 0.6538 - val_accuracy: 0.7455\n",
            "Epoch 66/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6629 - accuracy: 0.7452 - val_loss: 0.6479 - val_accuracy: 0.7533\n",
            "Epoch 67/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6662 - accuracy: 0.7451 - val_loss: 0.6258 - val_accuracy: 0.7607\n",
            "Epoch 68/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6624 - accuracy: 0.7505 - val_loss: 0.6271 - val_accuracy: 0.7580\n",
            "Epoch 69/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6577 - accuracy: 0.7499 - val_loss: 0.6504 - val_accuracy: 0.7470\n",
            "Epoch 70/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6635 - accuracy: 0.7478 - val_loss: 0.6326 - val_accuracy: 0.7525\n",
            "Epoch 71/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6531 - accuracy: 0.7528 - val_loss: 0.6282 - val_accuracy: 0.7565\n",
            "Epoch 72/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6469 - accuracy: 0.7556 - val_loss: 0.6006 - val_accuracy: 0.7662\n",
            "Epoch 73/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6496 - accuracy: 0.7540 - val_loss: 0.6243 - val_accuracy: 0.7653\n",
            "Epoch 74/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6426 - accuracy: 0.7535 - val_loss: 0.6076 - val_accuracy: 0.7637\n",
            "Epoch 75/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6366 - accuracy: 0.7565 - val_loss: 0.6026 - val_accuracy: 0.7693\n",
            "Epoch 76/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6287 - accuracy: 0.7610 - val_loss: 0.6095 - val_accuracy: 0.7693\n",
            "Epoch 77/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6286 - accuracy: 0.7593 - val_loss: 0.6018 - val_accuracy: 0.7703\n",
            "Epoch 78/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6308 - accuracy: 0.7589 - val_loss: 0.5915 - val_accuracy: 0.7700\n",
            "Epoch 79/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6251 - accuracy: 0.7593 - val_loss: 0.5910 - val_accuracy: 0.7633\n",
            "Epoch 80/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6223 - accuracy: 0.7618 - val_loss: 0.5958 - val_accuracy: 0.7718\n",
            "Epoch 81/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6077 - accuracy: 0.7676 - val_loss: 0.5710 - val_accuracy: 0.7768\n",
            "Epoch 82/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6024 - accuracy: 0.7684 - val_loss: 0.5828 - val_accuracy: 0.7730\n",
            "Epoch 83/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.6032 - accuracy: 0.7663 - val_loss: 0.5787 - val_accuracy: 0.7767\n",
            "Epoch 84/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5965 - accuracy: 0.7679 - val_loss: 0.5712 - val_accuracy: 0.7772\n",
            "Epoch 85/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5986 - accuracy: 0.7726 - val_loss: 0.5709 - val_accuracy: 0.7790\n",
            "Epoch 86/200\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.5985 - accuracy: 0.7698 - val_loss: 0.5659 - val_accuracy: 0.7797\n",
            "Epoch 87/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5980 - accuracy: 0.7729 - val_loss: 0.5624 - val_accuracy: 0.7817\n",
            "Epoch 88/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5909 - accuracy: 0.7717 - val_loss: 0.5683 - val_accuracy: 0.7753\n",
            "Epoch 89/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5829 - accuracy: 0.7780 - val_loss: 0.5592 - val_accuracy: 0.7852\n",
            "Epoch 90/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5815 - accuracy: 0.7775 - val_loss: 0.5458 - val_accuracy: 0.7882\n",
            "Epoch 91/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5678 - accuracy: 0.7802 - val_loss: 0.5686 - val_accuracy: 0.7768\n",
            "Epoch 92/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5717 - accuracy: 0.7779 - val_loss: 0.5447 - val_accuracy: 0.7892\n",
            "Epoch 93/200\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.5637 - accuracy: 0.7815 - val_loss: 0.5353 - val_accuracy: 0.7915\n",
            "Epoch 94/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5558 - accuracy: 0.7857 - val_loss: 0.5379 - val_accuracy: 0.7868\n",
            "Epoch 95/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5560 - accuracy: 0.7840 - val_loss: 0.5444 - val_accuracy: 0.7867\n",
            "Epoch 96/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5601 - accuracy: 0.7816 - val_loss: 0.5282 - val_accuracy: 0.7930\n",
            "Epoch 97/200\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.5476 - accuracy: 0.7839 - val_loss: 0.5251 - val_accuracy: 0.7962\n",
            "Epoch 98/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5428 - accuracy: 0.7898 - val_loss: 0.5278 - val_accuracy: 0.7928\n",
            "Epoch 99/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5412 - accuracy: 0.7889 - val_loss: 0.5258 - val_accuracy: 0.7948\n",
            "Epoch 100/200\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.5374 - accuracy: 0.7909 - val_loss: 0.5257 - val_accuracy: 0.7920\n",
            "Epoch 101/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5405 - accuracy: 0.7887 - val_loss: 0.5270 - val_accuracy: 0.7920\n",
            "Epoch 102/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5394 - accuracy: 0.7885 - val_loss: 0.5118 - val_accuracy: 0.8003\n",
            "Epoch 103/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5313 - accuracy: 0.7914 - val_loss: 0.5240 - val_accuracy: 0.7935\n",
            "Epoch 104/200\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.5214 - accuracy: 0.7950 - val_loss: 0.5134 - val_accuracy: 0.8043\n",
            "Epoch 105/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5233 - accuracy: 0.7955 - val_loss: 0.5088 - val_accuracy: 0.8022\n",
            "Epoch 106/200\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.5244 - accuracy: 0.7969 - val_loss: 0.5249 - val_accuracy: 0.7945\n",
            "Epoch 107/200\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.5251 - accuracy: 0.7917 - val_loss: 0.5013 - val_accuracy: 0.8045\n",
            "Epoch 108/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5100 - accuracy: 0.7994 - val_loss: 0.5061 - val_accuracy: 0.8053\n",
            "Epoch 109/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5074 - accuracy: 0.8013 - val_loss: 0.4909 - val_accuracy: 0.8083\n",
            "Epoch 110/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5089 - accuracy: 0.7981 - val_loss: 0.5133 - val_accuracy: 0.8008\n",
            "Epoch 111/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5055 - accuracy: 0.8004 - val_loss: 0.5065 - val_accuracy: 0.8083\n",
            "Epoch 112/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.5085 - accuracy: 0.7986 - val_loss: 0.4921 - val_accuracy: 0.8083\n",
            "Epoch 113/200\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.5000 - accuracy: 0.8041 - val_loss: 0.4880 - val_accuracy: 0.8135\n",
            "Epoch 114/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4941 - accuracy: 0.8050 - val_loss: 0.4937 - val_accuracy: 0.8032\n",
            "Epoch 115/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4908 - accuracy: 0.8073 - val_loss: 0.4947 - val_accuracy: 0.8112\n",
            "Epoch 116/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4885 - accuracy: 0.8065 - val_loss: 0.4836 - val_accuracy: 0.8122\n",
            "Epoch 117/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4861 - accuracy: 0.8083 - val_loss: 0.5142 - val_accuracy: 0.8025\n",
            "Epoch 118/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4818 - accuracy: 0.8075 - val_loss: 0.4789 - val_accuracy: 0.8078\n",
            "Epoch 119/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4829 - accuracy: 0.8077 - val_loss: 0.4773 - val_accuracy: 0.8095\n",
            "Epoch 120/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4760 - accuracy: 0.8101 - val_loss: 0.4815 - val_accuracy: 0.8172\n",
            "Epoch 121/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4791 - accuracy: 0.8125 - val_loss: 0.4755 - val_accuracy: 0.8153\n",
            "Epoch 122/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4724 - accuracy: 0.8131 - val_loss: 0.4737 - val_accuracy: 0.8183\n",
            "Epoch 123/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4741 - accuracy: 0.8095 - val_loss: 0.4719 - val_accuracy: 0.8145\n",
            "Epoch 124/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4696 - accuracy: 0.8185 - val_loss: 0.4830 - val_accuracy: 0.8163\n",
            "Epoch 125/200\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.4659 - accuracy: 0.8158 - val_loss: 0.4659 - val_accuracy: 0.8245\n",
            "Epoch 126/200\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.4751 - accuracy: 0.8138 - val_loss: 0.4912 - val_accuracy: 0.8150\n",
            "Epoch 127/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4603 - accuracy: 0.8162 - val_loss: 0.4706 - val_accuracy: 0.8187\n",
            "Epoch 128/200\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 0.4627 - accuracy: 0.8157 - val_loss: 0.4651 - val_accuracy: 0.8210\n",
            "Epoch 129/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4712 - accuracy: 0.8160 - val_loss: 0.4941 - val_accuracy: 0.8098\n",
            "Epoch 130/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4601 - accuracy: 0.8172 - val_loss: 0.4720 - val_accuracy: 0.8232\n",
            "Epoch 131/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4582 - accuracy: 0.8163 - val_loss: 0.4679 - val_accuracy: 0.8220\n",
            "Epoch 132/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4485 - accuracy: 0.8209 - val_loss: 0.4630 - val_accuracy: 0.8235\n",
            "Epoch 133/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4492 - accuracy: 0.8212 - val_loss: 0.4788 - val_accuracy: 0.8185\n",
            "Epoch 134/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4517 - accuracy: 0.8196 - val_loss: 0.4744 - val_accuracy: 0.8200\n",
            "Epoch 135/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4524 - accuracy: 0.8203 - val_loss: 0.4629 - val_accuracy: 0.8218\n",
            "Epoch 136/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4464 - accuracy: 0.8236 - val_loss: 0.4687 - val_accuracy: 0.8260\n",
            "Epoch 137/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4397 - accuracy: 0.8267 - val_loss: 0.4650 - val_accuracy: 0.8220\n",
            "Epoch 138/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4443 - accuracy: 0.8239 - val_loss: 0.4645 - val_accuracy: 0.8213\n",
            "Epoch 139/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4373 - accuracy: 0.8228 - val_loss: 0.4603 - val_accuracy: 0.8212\n",
            "Epoch 140/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4382 - accuracy: 0.8280 - val_loss: 0.4657 - val_accuracy: 0.8237\n",
            "Epoch 141/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4389 - accuracy: 0.8256 - val_loss: 0.4558 - val_accuracy: 0.8263\n",
            "Epoch 142/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4343 - accuracy: 0.8254 - val_loss: 0.4634 - val_accuracy: 0.8290\n",
            "Epoch 143/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4325 - accuracy: 0.8278 - val_loss: 0.4548 - val_accuracy: 0.8255\n",
            "Epoch 144/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4313 - accuracy: 0.8272 - val_loss: 0.4623 - val_accuracy: 0.8242\n",
            "Epoch 145/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4273 - accuracy: 0.8302 - val_loss: 0.4594 - val_accuracy: 0.8255\n",
            "Epoch 146/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4242 - accuracy: 0.8301 - val_loss: 0.4485 - val_accuracy: 0.8302\n",
            "Epoch 147/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4188 - accuracy: 0.8325 - val_loss: 0.4504 - val_accuracy: 0.8352\n",
            "Epoch 148/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4163 - accuracy: 0.8333 - val_loss: 0.4543 - val_accuracy: 0.8268\n",
            "Epoch 149/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4336 - accuracy: 0.8279 - val_loss: 0.4886 - val_accuracy: 0.8188\n",
            "Epoch 150/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4240 - accuracy: 0.8317 - val_loss: 0.4469 - val_accuracy: 0.8327\n",
            "Epoch 151/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4220 - accuracy: 0.8326 - val_loss: 0.4589 - val_accuracy: 0.8332\n",
            "Epoch 152/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4081 - accuracy: 0.8373 - val_loss: 0.4503 - val_accuracy: 0.8352\n",
            "Epoch 153/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4133 - accuracy: 0.8354 - val_loss: 0.4527 - val_accuracy: 0.8268\n",
            "Epoch 154/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4100 - accuracy: 0.8374 - val_loss: 0.4509 - val_accuracy: 0.8302\n",
            "Epoch 155/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4187 - accuracy: 0.8359 - val_loss: 0.4494 - val_accuracy: 0.8283\n",
            "Epoch 156/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4125 - accuracy: 0.8372 - val_loss: 0.4434 - val_accuracy: 0.8355\n",
            "Epoch 157/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3985 - accuracy: 0.8395 - val_loss: 0.4417 - val_accuracy: 0.8323\n",
            "Epoch 158/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4089 - accuracy: 0.8363 - val_loss: 0.4457 - val_accuracy: 0.8298\n",
            "Epoch 159/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4000 - accuracy: 0.8399 - val_loss: 0.4538 - val_accuracy: 0.8317\n",
            "Epoch 160/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4084 - accuracy: 0.8381 - val_loss: 0.4510 - val_accuracy: 0.8288\n",
            "Epoch 161/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.4158 - accuracy: 0.8361 - val_loss: 0.4403 - val_accuracy: 0.8338\n",
            "Epoch 162/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3974 - accuracy: 0.8395 - val_loss: 0.4477 - val_accuracy: 0.8352\n",
            "Epoch 163/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3925 - accuracy: 0.8418 - val_loss: 0.4489 - val_accuracy: 0.8323\n",
            "Epoch 164/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3931 - accuracy: 0.8437 - val_loss: 0.4471 - val_accuracy: 0.8335\n",
            "Epoch 165/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3992 - accuracy: 0.8430 - val_loss: 0.4426 - val_accuracy: 0.8372\n",
            "Epoch 166/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3851 - accuracy: 0.8458 - val_loss: 0.4444 - val_accuracy: 0.8397\n",
            "Epoch 167/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3918 - accuracy: 0.8443 - val_loss: 0.4405 - val_accuracy: 0.8327\n",
            "Epoch 168/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3921 - accuracy: 0.8425 - val_loss: 0.4484 - val_accuracy: 0.8277\n",
            "Epoch 169/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3822 - accuracy: 0.8456 - val_loss: 0.4415 - val_accuracy: 0.8385\n",
            "Epoch 170/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3956 - accuracy: 0.8433 - val_loss: 0.4467 - val_accuracy: 0.8363\n",
            "Epoch 171/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3789 - accuracy: 0.8447 - val_loss: 0.4372 - val_accuracy: 0.8347\n",
            "Epoch 172/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3763 - accuracy: 0.8490 - val_loss: 0.4461 - val_accuracy: 0.8365\n",
            "Epoch 173/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3788 - accuracy: 0.8487 - val_loss: 0.4416 - val_accuracy: 0.8378\n",
            "Epoch 174/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3736 - accuracy: 0.8533 - val_loss: 0.4407 - val_accuracy: 0.8358\n",
            "Epoch 175/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3889 - accuracy: 0.8469 - val_loss: 0.4396 - val_accuracy: 0.8355\n",
            "Epoch 176/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3779 - accuracy: 0.8465 - val_loss: 0.4398 - val_accuracy: 0.8343\n",
            "Epoch 177/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3883 - accuracy: 0.8479 - val_loss: 0.4565 - val_accuracy: 0.8313\n",
            "Epoch 178/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3925 - accuracy: 0.8416 - val_loss: 0.4485 - val_accuracy: 0.8342\n",
            "Epoch 179/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3771 - accuracy: 0.8483 - val_loss: 0.4351 - val_accuracy: 0.8383\n",
            "Epoch 180/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3712 - accuracy: 0.8534 - val_loss: 0.4347 - val_accuracy: 0.8388\n",
            "Epoch 181/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3624 - accuracy: 0.8543 - val_loss: 0.4304 - val_accuracy: 0.8390\n",
            "Epoch 182/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3645 - accuracy: 0.8541 - val_loss: 0.4341 - val_accuracy: 0.8387\n",
            "Epoch 183/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3627 - accuracy: 0.8565 - val_loss: 0.4427 - val_accuracy: 0.8378\n",
            "Epoch 184/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3625 - accuracy: 0.8549 - val_loss: 0.4458 - val_accuracy: 0.8387\n",
            "Epoch 185/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3575 - accuracy: 0.8586 - val_loss: 0.4420 - val_accuracy: 0.8350\n",
            "Epoch 186/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3634 - accuracy: 0.8558 - val_loss: 0.4403 - val_accuracy: 0.8370\n",
            "Epoch 187/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3560 - accuracy: 0.8585 - val_loss: 0.4394 - val_accuracy: 0.8342\n",
            "Epoch 188/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3534 - accuracy: 0.8596 - val_loss: 0.4333 - val_accuracy: 0.8390\n",
            "Epoch 189/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3570 - accuracy: 0.8567 - val_loss: 0.4435 - val_accuracy: 0.8398\n",
            "Epoch 190/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3604 - accuracy: 0.8558 - val_loss: 0.4399 - val_accuracy: 0.8360\n",
            "Epoch 191/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3544 - accuracy: 0.8564 - val_loss: 0.4366 - val_accuracy: 0.8373\n",
            "Epoch 192/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3515 - accuracy: 0.8601 - val_loss: 0.4302 - val_accuracy: 0.8393\n",
            "Epoch 193/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3622 - accuracy: 0.8578 - val_loss: 0.4524 - val_accuracy: 0.8328\n",
            "Epoch 194/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3629 - accuracy: 0.8556 - val_loss: 0.4394 - val_accuracy: 0.8373\n",
            "Epoch 195/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3795 - accuracy: 0.8516 - val_loss: 0.4598 - val_accuracy: 0.8307\n",
            "Epoch 196/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3625 - accuracy: 0.8555 - val_loss: 0.4394 - val_accuracy: 0.8383\n",
            "Epoch 197/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3489 - accuracy: 0.8594 - val_loss: 0.4401 - val_accuracy: 0.8378\n",
            "Epoch 198/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3575 - accuracy: 0.8567 - val_loss: 0.4371 - val_accuracy: 0.8392\n",
            "Epoch 199/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3519 - accuracy: 0.8574 - val_loss: 0.4366 - val_accuracy: 0.8360\n",
            "Epoch 200/200\n",
            "200/200 [==============================] - 2s 8ms/step - loss: 0.3581 - accuracy: 0.8578 - val_loss: 0.4456 - val_accuracy: 0.8387\n"
          ]
        }
      ],
      "source": [
        "#모델 학습실행하는 명령\n",
        "with tf.device(\"GPU:0\"):\n",
        "    tracker = model.fit(xTrain, yTrain,\n",
        "                    batch_size=120,\n",
        "                    epochs=200,\n",
        "                    validation_data=(xValidation, yValidation),\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "\n",
        "stringTime = datetime.today().astimezone(timezone('asia/Seoul')).strftime(\"%Y-%m-%d %H-%M-%S\")\n",
        "pathString = f\"{BASE_DIR}/output/{stringTime}\"\n",
        "if not os.path.exists(pathString):\n",
        "  os.makedirs(pathString)"
      ],
      "metadata": {
        "id": "veSrXUddEpRY"
      },
      "id": "veSrXUddEpRY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea8f98e4-fa8e-42d8-9fc2-c96e05cb3390",
      "metadata": {
        "id": "ea8f98e4-fa8e-42d8-9fc2-c96e05cb3390"
      },
      "outputs": [],
      "source": [
        "modelDescription = model.to_json()\n",
        "with open(f\"{pathString}/model.json\", \"w\") as fileModel:\n",
        "  fileModel.write(modelDescription)\n",
        "model.save_weights(f\"{pathString}/model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "historyJson = tracker.history\n",
        "json.dump(historyJson, open(f\"{pathString}/tracker.json\", \"w\"))"
      ],
      "metadata": {
        "id": "U3u8KZ7yFUgE"
      },
      "id": "U3u8KZ7yFUgE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}